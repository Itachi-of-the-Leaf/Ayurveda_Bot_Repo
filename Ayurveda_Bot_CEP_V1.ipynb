{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ce6d558-2b0e-4ccb-9205-14dbd78ee980",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import json\n",
    "import logging\n",
    "from traceback import format_exc\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Web Server & Framework\n",
    "from flask import Flask, request\n",
    "from flask_limiter import Limiter\n",
    "from flask_limiter.util import get_remote_address\n",
    "\n",
    "# API Clients\n",
    "import requests\n",
    "from twilio.rest import Client\n",
    "from googleapiclient.discovery import build\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Media & AI Processing\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from faster_whisper import WhisperModel\n",
    "\n",
    "#Google Text to Speech\n",
    "import uuid\n",
    "from gtts import gTTS\n",
    "from flask import send_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a2c341c-1670-4547-901d-15f6195e1861",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soham/miniconda3/envs/ayurveda_bot_env/lib/python3.11/site-packages/flask_limiter/extension.py:324: UserWarning: Using the in-memory storage for tracking rate limits as no storage was explicitly specified. This is not recommended for production use. See: https://flask-limiter.readthedocs.io#configuring-a-storage-backend for documentation about configuring the storage backend.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# --- INITIALIZATION AND CONFIGURATION ---\n",
    "\n",
    "load_dotenv() # Load environment variables from .env file\n",
    "app = Flask(__name__)\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "limiter = Limiter(app=app, key_func=get_remote_address, default_limits=[\"2000 per day\", \"500 per hour\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173ebb85-6d3c-4bfb-8940-7dd4022cea10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- API CLIENTS AND ENVIRONMENT VARIABLES ---\n",
    "\n",
    "# Securely loading keys from environment variables\n",
    "# --- Configuration: get keys from environment ---\n",
    "TWILIO_ACCOUNT_SID = \"\"\n",
    "TWILIO_AUTH_TOKEN = \"\"\n",
    "GOOGLE_AI_API_KEY = \"\"\n",
    "GOOGLE_API_KEY = \"\"\n",
    "GOOGLE_CSE_ID = \"\"\n",
    "TWILIO_WHATSAPP_NUMBER = 'whatsapp:+14155238886'\n",
    "\n",
    "#GTTS Stuff\n",
    "NGROK_PUBLIC_URL = \"\" \n",
    "\n",
    "# Create a directory to store the audio files\n",
    "AUDIO_DIR = \"/tmp/vaidya_audio\" \n",
    "os.makedirs(AUDIO_DIR, exist_ok=True)\n",
    "\n",
    "# Validate that all necessary credentials are set\n",
    "if not all([TWILIO_ACCOUNT_SID, TWILIO_AUTH_TOKEN, GOOGLE_API_KEY, GOOGLE_CSE_ID, GOOGLE_AI_API_KEY]):\n",
    "    raise EnvironmentError(\"One or more required environment variables are not set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba71c0c5-9774-4938-a991-b1d3d20f9d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize API clients\n",
    "twilio_client = Client(TWILIO_ACCOUNT_SID, TWILIO_AUTH_TOKEN)\n",
    "genai.configure(api_key=GOOGLE_AI_API_KEY)\n",
    "gemini_model = genai.GenerativeModel('gemini-2.5-flash')\n",
    "audio_model = WhisperModel(\"base\", device=\"cuda\", compute_type=\"float16\")\n",
    "vision_weights = ResNet18_Weights.DEFAULT\n",
    "vision_model = resnet18(weights=vision_weights)\n",
    "vision_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcf85f5f-11bb-49b8-bce9-e934c4595e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONVERSATION MEMORY ---\n",
    "# Bot's memory is a simple dictionary that resets on server restart.\n",
    "conversation_states = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b267c76f-be50-41cc-a3b7-d4acd4fd9b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- AI SERVICES ---\n",
    "\n",
    "def get_conversational_reply(history):\n",
    "    \"\"\"Generates a natural, conversational reply from Gemini.\"\"\"\n",
    "    history_str = \"\\n\".join([f\"{msg['role']}: {msg['content']}\" for msg in history])\n",
    "    prompt = (\n",
    "        \"You are VaidyaAI, a warm, empathetic, and insightful AI health companion rooted in the wisdom of Ayurveda. Your goal is to have a natural, free-flowing conversation to help a user understand their health concerns.\"\n",
    "        \"\\n\\n**Your Core Rules:**\\n\"\n",
    "        \"1.  **Be Conversational:** Talk like a caring, knowledgeable guide, not a robot. Ask questions naturally to understand symptoms (nature, duration, intensity).\\n\"\n",
    "        \"2.  **Safety First:** NEVER give a medical diagnosis or prescribe specific dosages. Always include disclaimers and advise consulting a qualified practitioner.\\n\"\n",
    "        \"3.  **Stay Focused:** If the user talks about unrelated topics, gently guide them back by saying, 'That's interesting, but my main purpose is to help with your wellness. How can I assist you with that today?'\\n\"\n",
    "        \"4.  **Implicitly Understand:** When you have enough information and the user asks for a remedy, provide one in a structured, easy-to-read format using Markdown with bold asterisks for headings.\\n\\n\"\n",
    "        f\"**Current Conversation:**\\n{history_str}\\nassistant: \"\n",
    "    )\n",
    "    try:\n",
    "        response = gemini_model.generate_content(prompt)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Gemini API call failed: {e}\")\n",
    "        return \"I'm sorry, I'm having trouble connecting to my knowledge base at the moment.\"\n",
    "\n",
    "# --- MEDIA ANALYSIS ---\n",
    "\n",
    "def transcribe_audio(audio_bytes):\n",
    "    \"\"\"Transcribes audio bytes to text using Whisper.\"\"\"\n",
    "    try:\n",
    "        temp_audio_path = \"/tmp/temp_audio.ogg\"\n",
    "        with open(temp_audio_path, \"wb\") as f: f.write(audio_bytes)\n",
    "        segments, _ = audio_model.transcribe(temp_audio_path, beam_size=5)\n",
    "        return \"\".join(segment.text for segment in segments).strip()\n",
    "    except Exception: return \"Error transcribing audio.\"\n",
    "\n",
    "def process_image_bytes(image_bytes):\n",
    "    \"\"\"Performs OCR on the raw bytes of an image.\"\"\"\n",
    "    try:\n",
    "        return pytesseract.image_to_string(Image.open(io.BytesIO(image_bytes))).strip()\n",
    "    except Exception: return \"\"\n",
    "\n",
    "def recognize_image_content(image_bytes):\n",
    "    \"\"\"Uses a ResNet model to identify the main object in an image.\"\"\"\n",
    "    try:\n",
    "        labels = vision_weights.meta[\"categories\"]\n",
    "        preprocess = vision_weights.transforms()\n",
    "        image = Image.open(io.BytesIO(image_bytes)).convert(\"RGB\")\n",
    "        batch = preprocess(image).unsqueeze(0)\n",
    "        prediction = vision_model(batch).squeeze(0).softmax(0)\n",
    "        class_id = prediction.argmax().item()\n",
    "        score = prediction[class_id].item()\n",
    "        return labels[class_id] if score > 0.1 else \"\"\n",
    "    except Exception: return \"\"\n",
    "\n",
    "def analyze_image(image_bytes):\n",
    "    \"\"\"Analyzes an image by first trying OCR, then falling back to image recognition.\"\"\"\n",
    "    ocr_text = process_image_bytes(image_bytes)\n",
    "    return ocr_text if ocr_text and len(ocr_text) > 5 else recognize_image_content(image_bytes)\n",
    "\n",
    "# --- UTILITIES ---\n",
    "\n",
    "def soft_shorten_message(full_text):\n",
    "    \"\"\"\n",
    "    Intelligently shortens a message to fit within the 1600 character limit\n",
    "    by truncating at the end of the last full sentence that fits.\n",
    "    \"\"\"\n",
    "    limit = 1600\n",
    "    if len(full_text) <= limit:\n",
    "        return full_text\n",
    "\n",
    "    logging.warning(\"Message exceeds 1600 characters, performing soft shortening.\")\n",
    "    \n",
    "    # Isolate the main body from the disclaimer we always want to include\n",
    "    disclaimer = \"\\n\\n*Disclaimer: This is AI-generated advice. Please consult a qualified practitioner.*\"\n",
    "    text_body = full_text.replace(disclaimer, \"\").strip()\n",
    "    notice = \"\\n\\n...(message shortened for brevity)\"\n",
    "    \n",
    "    # Calculate the maximum possible length for the main text body\n",
    "    max_body_len = limit - len(notice) - len(disclaimer)\n",
    "    \n",
    "    if len(text_body) <= max_body_len:\n",
    "        return full_text # Should not happen, but a good safeguard\n",
    "\n",
    "    # Find the last period (end of a sentence) before the maximum allowed length\n",
    "    cut_off_point = text_body.rfind('.', 0, max_body_len)\n",
    "    \n",
    "    if cut_off_point != -1:\n",
    "        # If a period is found, cut the message cleanly at the end of that sentence\n",
    "        shortened_body = text_body[:cut_off_point + 1]\n",
    "    else:\n",
    "        # If no period is found (e.g., one very long paragraph), perform the hard truncate as a last resort\n",
    "        shortened_body = text_body[:max_body_len]\n",
    "\n",
    "    return shortened_body.strip() + notice + disclaimer\n",
    "\n",
    "def find_image_url(query):\n",
    "    \"\"\"Uses Google Custom Search to find an image URL.\"\"\"\n",
    "    try:\n",
    "        service = build(\"customsearch\", \"v1\", developerKey=GOOGLE_API_KEY)\n",
    "        res = service.cse().list(q=query, cx=GOOGLE_CSE_ID, searchType='image', num=1, safe='high').execute()\n",
    "        return res['items'][0]['link'] if 'items' in res and len(res['items']) > 0 else None\n",
    "    except Exception: return None\n",
    "\n",
    "def get_media_content(message_sid):\n",
    "    \"\"\"Securely fetches media content from Twilio.\"\"\"\n",
    "    try:\n",
    "        media_list = twilio_client.messages(message_sid).media.list()\n",
    "        if not media_list: return None\n",
    "        media_instance = media_list[0]\n",
    "        media_url = f\"https://api.twilio.com{media_instance.uri.replace('.json', '')}\"\n",
    "        response = requests.get(media_url, auth=(TWILIO_ACCOUNT_SID, TWILIO_AUTH_TOKEN))\n",
    "        response.raise_for_status()\n",
    "        return response.content\n",
    "    except Exception: return None\n",
    "\n",
    "def send_whatsapp_message(to_number, message_body, media_url=None):\n",
    "    \"\"\"Sends a message via Twilio, optionally with a single media file (image or audio).\"\"\"\n",
    "    try:\n",
    "        message_args = {'from_': TWILIO_WHATSAPP_NUMBER, 'to': to_number, 'body': message_body}\n",
    "        \n",
    "        if media_url:\n",
    "            # Check if it's a valid media type Twilio supports\n",
    "            if media_url.lower().endswith(('.png', '.jpg', '.jpeg', '.mp3', '.ogg')):\n",
    "                 message_args['media_url'] = [media_url]\n",
    "            else:\n",
    "                logging.warning(f\"Unsupported media_url skipped: {media_url}\")\n",
    "                \n",
    "        twilio_client.messages.create(**message_args)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Twilio API error: {format_exc()}\")\n",
    "\n",
    "@app.route('/audio/<filename>')\n",
    "def serve_audio(filename):\n",
    "    \"\"\"Serves static audio files from the tmp directory.\"\"\"\n",
    "    try:\n",
    "        return send_from_directory(AUDIO_DIR, filename)\n",
    "    except FileNotFoundError:\n",
    "        return \"Audio file not found\", 404\n",
    "\n",
    "def generate_tts_audio_url(text_to_speak):\n",
    "    \"\"\"Generates a TTS audio file, saves it, and returns the public URL.\"\"\"\n",
    "    try:\n",
    "        if not NGROK_PUBLIC_URL or \"YOUR-UNIQUE-ID\" in NGROK_PUBLIC_URL:\n",
    "            logging.warning(\"NGROK_PUBLIC_URL not set. Skipping TTS.\")\n",
    "            return None\n",
    "\n",
    "        # Clean text for speech\n",
    "        text_to_speak = text_to_speak.replace(\"*\", \"\") # Remove markdown\n",
    "\n",
    "        tts = gTTS(text=text_to_speak, lang='en')\n",
    "        filename = f\"{uuid.uuid4()}.mp3\"\n",
    "        filepath = os.path.join(AUDIO_DIR, filename)\n",
    "        tts.save(filepath)\n",
    "\n",
    "        # Build the public URL for Twilio\n",
    "        public_url = f\"{NGROK_PUBLIC_URL}/audio/{filename}\"\n",
    "        return public_url\n",
    "    except Exception as e:\n",
    "        logging.error(f\"TTS generation failed: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbb25d49-43c3-4e3f-951f-e3c0690b07ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MAIN WEBHOOK ---\n",
    "\n",
    "@app.route('/webhook', methods=['POST'])\n",
    "@limiter.limit(\"100 per minute\")\n",
    "def webhook():\n",
    "    from_number = request.form.get('From')\n",
    "    incoming_msg_body = request.form.get('Body', '').strip()\n",
    "    \n",
    "    if from_number not in conversation_states:\n",
    "        conversation_states[from_number] = {'history': []}\n",
    "    state_data = conversation_states[from_number]\n",
    "    history = state_data['history']\n",
    "    \n",
    "    media_text = \"\"\n",
    "    is_audio_message = False # Flag to track if user sent audio\n",
    "    \n",
    "    if int(request.form.get('NumMedia', 0)) > 0:\n",
    "        media_bytes = get_media_content(request.form.get('MessageSid')) \n",
    "        if media_bytes:\n",
    "            media_type = request.form.get('MediaContentType0', '')\n",
    "            if 'audio' in media_type:\n",
    "                is_audio_message = True\n",
    "                media_text = transcribe_audio(media_bytes)\n",
    "            else:\n",
    "                media_text = analyze_image(media_bytes)\n",
    "\n",
    "    # --- Format the full incoming message with context ---\n",
    "    full_incoming_msg = \"\"\n",
    "    if media_text and incoming_msg_body:\n",
    "        full_incoming_msg = f\"User sent a media file (content analyzed as: '{media_text}') and also typed: '{incoming_msg_body}'\"\n",
    "    elif media_text:\n",
    "        full_incoming_msg = f\"User sent a media file. The content I extracted from it is: '{media_text}'. Please respond to this in the context of our conversation.\"\n",
    "    elif incoming_msg_body:\n",
    "        full_incoming_msg = incoming_msg_body\n",
    "    else:\n",
    "        return '', 200 # Ignore empty messages\n",
    "\n",
    "    history.append({'role': 'user', 'content': full_incoming_msg})\n",
    "    \n",
    "    reply_text, image_url = \"\", None\n",
    "    \n",
    "    if full_incoming_msg.lower().startswith(\"show me a picture of\"):\n",
    "        query = full_incoming_msg[len(\"show me a picture of\"):].strip()\n",
    "        if query:\n",
    "            image_url = find_image_url(query) \n",
    "            if image_url:\n",
    "                reply_text = f\"Here is a picture of {query}.\"\n",
    "            else:\n",
    "                reply_text = f\"I'm sorry, I couldn't find a picture of {query}.\"\n",
    "        else:\n",
    "            reply_text = \"Please tell me what you want to see a picture of.\"\n",
    "    else:\n",
    "        reply_text = get_conversational_reply(history)\n",
    "\n",
    "    if not reply_text: \n",
    "        reply_text = \"I'm sorry, I'm having a bit of trouble at the moment.\"\n",
    "    \n",
    "    history.append({'role': 'assistant', 'content': reply_text})\n",
    "    \n",
    "    disclaimer = \"\\n\\n*Disclaimer: This is AI-generated advice. Please consult a qualified practitioner.*\"\n",
    "    full_reply = reply_text + disclaimer\n",
    "    final_message = soft_shorten_message(full_reply)\n",
    "    \n",
    "    # --- Media Reply Logic: Prioritize Image, then Audio ---\n",
    "    media_to_send_url = None\n",
    "    if image_url:\n",
    "        # Priority 1: Send the image if one was found\n",
    "        media_to_send_url = image_url\n",
    "    elif is_audio_message:\n",
    "        # Priority 2: If user sent audio (and we're not sending an image), reply with audio\n",
    "        # We send the *original* text to TTS, not the one with the disclaimer.\n",
    "        media_to_send_url = generate_tts_audio_url(reply_text)\n",
    "\n",
    "    send_whatsapp_message(from_number, final_message, media_to_send_url)\n",
    "    \n",
    "    return '', 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b52f07f-58df-4d16-b979-73467fd8ed39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 14:54:10,362 - INFO - \u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://172.17.213.47:5000\n",
      "2025-11-16 14:54:10,363 - INFO - \u001b[33mPress CTRL+C to quit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# --- MAIN EXECUTION ---\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1811c8db-003d-4416-ac01-bb7420f2810f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
